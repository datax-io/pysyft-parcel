{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model-Centric Federated Learning for Mobile - MNIST Example\n",
    "\n",
    "This notebook will walk you through creating a simple model and a training plan, and hosting both as a federated learning process\n",
    "for further training using OpenMined mobile FL workers.\n",
    "\n",
    "This notebook is similar to \"[MCFL - Create Plan](mcfl_create_plan.ipynb)\"\n",
    "however due to mobile limitations, the training plan is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import base64\n",
    "import json\n",
    "\n",
    "# third party\n",
    "import torch as th\n",
    "\n",
    "# syft absolute\n",
    "import syft as sy\n",
    "from syft.core.plan.plan_builder import ROOT_CLIENT\n",
    "from syft.core.plan.plan_builder import PLAN_BUILDER_VM\n",
    "from syft.core.plan.plan_builder import make_plan\n",
    "from syft.core.plan.translation.torchscript.plan_translate import (\n",
    "    translate as translate_to_ts,\n",
    ")\n",
    "from syft.federated.model_centric_fl_client import ModelCentricFLClient\n",
    "from syft.lib.python.int import Int\n",
    "from syft.lib.python.list import List\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2d200c6310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.random.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the model\n",
    "\n",
    "This model will train on MNIST data, it's very simple yet can demonstrate learning process.\n",
    "There're 2 linear layers: \n",
    "\n",
    "* Linear 784x100\n",
    "* ReLU\n",
    "* Linear 100x10 \n",
    "\n",
    "Note that the model contains additional methods for convenience of torch reference usage:\n",
    "\n",
    "* `backward` - calculates backward pass gradients because autograd doesn't work on mobile (yet).\n",
    "* `softmax_cross_entropy_with_logits` - loss function\n",
    "* `accuracy` - calculates accuracy of prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our knowledge\n",
    "1. grads for FCN ==> weight/grad/weight/grad ... From earliest to latest. Weight expand from later to earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(sy.Module): #This version follows hinnes' implmentation (first assume only one user and using numeric attributes of the song)\n",
    "    \"\"\"\n",
    "    Simple model with method for loss and hand-written backprop.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, torch_ref,n_users) -> None:\n",
    "        super(EmbeddingNet, self).__init__(torch_ref=torch_ref)\n",
    "        #This is purely fully connected.\n",
    "        # def gen_layers(n_in):\n",
    "        #     \"\"\"\n",
    "        #     A generator that yields a sequence of hidden layers and \n",
    "        #     their activations/dropouts.\n",
    "            \n",
    "        #     Note that the function captures `hidden` and `dropouts` \n",
    "        #     values from the outer scope.\n",
    "        #     \"\"\"\n",
    "        #     nonlocal hidden, dropouts\n",
    "        #     assert len(dropouts) <= len(hidden)\n",
    "            \n",
    "        #     for n_out, rate in zip_longest(hidden, dropouts):\n",
    "        #         yield torch_ref.nn.Linear(n_in, n_out)\n",
    "        #         yield torch_ref.nn.ReLU()\n",
    "        #         if rate is not None and rate > 0.:\n",
    "        #             yield torch_ref.nn.Dropout(rate)\n",
    "        #         n_in = n_out\n",
    "        self.torch_ref = torch_ref\n",
    "        self.embedlayer = torch_ref.nn.Embedding(n_users,50)\n",
    "        self.embeddrop = torch_ref.nn.Dropout(0.02)\n",
    "        self.fc1 = torch_ref.nn.Linear(60,50)\n",
    "        self.a1 = torch_ref.nn.ReLU()\n",
    "        self.d1 = torch_ref.nn.Dropout(0.25)\n",
    "        self.fc2 = torch_ref.nn.Linear(50,100)\n",
    "        self.a2 = torch_ref.nn.ReLU()\n",
    "        self.d2 = torch_ref.nn.Dropout(0.5)\n",
    "        self.fc3 = torch_ref.nn.Linear(100,75)\n",
    "        self.a3 = torch_ref.nn.ReLU()\n",
    "        self.fc4 = torch_ref.nn.Linear(75,1)\n",
    "        #layersizes contain the size of each layer, including output but exclude input\n",
    "\n",
    "\n",
    "    def forward(self, users,features):\n",
    "        self.embedout = self.embedlayer(users.long()) \n",
    "        x = th.cat((self.embedout.get(),features.get()),dim=1)\n",
    "        self.catout = self.embeddrop(x)\n",
    "        x = self.fc1(self.catout)\n",
    "        x = self.a1(x)\n",
    "        self.l1out = self.d1(x)\n",
    "        y = self.fc2(self.l1out)\n",
    "        y = self.a2(y)\n",
    "        self.l2out = self.d2(y)\n",
    "        z = self.fc3(self.l2out)\n",
    "        self.l3out = self.a3(z)\n",
    "        k = self.fc4(self.l3out)\n",
    "        self.l4out = self.torch_ref.sigmoid(k)\n",
    "        return self.l4out\n",
    "    \n",
    "    def one_hot(self,user,num):\n",
    "        y = []\n",
    "        user = user.get()\n",
    "        for use in user:\n",
    "            x = [0] * num\n",
    "            x[use] = 1\n",
    "            y.append(x)\n",
    "        return th.tensor(y,dtype=th.int32)\n",
    "\n",
    "    def backward(self,user,error): #BATCH_SIZE=1 is assumed.\n",
    "        pgs,flayers,aouts = [],[],[]\n",
    "        latest_grad = error\n",
    "        aouts.extend([self.catout,self.l1out,self.l2out,self.l3out])\n",
    "        flayers.extend([self.fc2,self.fc3,self.fc4])\n",
    "        for i in range(len(aouts)):\n",
    "            j = len(aouts) - i - 1\n",
    "            pgs.append(latest_grad.sum(0)) # bias grad\n",
    "            pgs.append(latest_grad.t() @ aouts[j]) # weight grad\n",
    "            # print(latest_grad.shape, self.flayers[j-1].state_dict()['weight'].shape, self.aouts[j].shape)\n",
    "            if j-1 >= 0:\n",
    "                latest_grad = (latest_grad @ flayers[j-1].state_dict()['weight']) * (aouts[j] > 0).float() \n",
    "            else: #Embedding layer\n",
    "                latest_grad = (latest_grad @ self.fc1.state_dict()['weight']) #no ReLU in embedding\n",
    "                latest_grad = latest_grad[:,:50]\n",
    "        user = self.one_hot(user,9)\n",
    "        embedgrad = latest_grad.t() @ user.float()\n",
    "        pgs.append(embedgrad.t())\n",
    "        pgs.reverse()\n",
    "        return tuple(pgs)\n",
    "    \n",
    "    def get_model_parameters(self):\n",
    "        params = []\n",
    "        for i,layer in enumerate(self.hiddens):\n",
    "            if i % 3 == 0 :\n",
    "                params.append(layer.state_dict()['weight'])\n",
    "                params.append(layer.state_dict()['bias'])\n",
    "        params.append(self.fc.state_dict()['weight'])\n",
    "        params.append(self.fc.state_dict()['bias'])\n",
    "        return params\n",
    "\n",
    "    def mse_loss(self, fpass, target, batch_size):# MSE first\n",
    "        squared_error = self.torch_ref.pow(fpass - target,2)\n",
    "        loss = squared_error.mean()\n",
    "        loss_grad = (target-fpass) * fpass * (1-fpass) / batch_size\n",
    "        return loss,loss_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_303705/3064731568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mxs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfpass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.9/site-packages/syft/lib/torch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     ) -> Any:\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_303705/2692893656.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, users, features)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "model = EmbeddingNet(th,n_users=9)\n",
    "\n",
    "\n",
    "# model.get_paremeters()\n",
    "xs = th.randn(32,10)\n",
    "xs2 = th.randint(1,8,(32,))\n",
    "fpass = model(xs2,xs)\n",
    "lr = 0.001\n",
    "bs = 32\n",
    "batch_size = th.tensor([bs])\n",
    "ys=th.rand(32,1)\n",
    "# # # print(ys)\n",
    "loss, loss_grad = model.mse_loss(fpass,ys,batch_size)\n",
    "# # # print(loss,loss_grad)\n",
    "# # print(model.flayers)\n",
    "# # # # backward\n",
    "print(\"Results here:\")\n",
    "grads = model.backward(xs2, loss_grad)\n",
    "# print(grads.shape)\n",
    "for x in grads:\n",
    "    print(x.shape)\n",
    "print(\"Results sdf here:\")\n",
    "for y in model.parameters():\n",
    "    print(y.shape)\n",
    "# updated_params = tuple(\n",
    "#         param - lr * grad for param, grad in zip(model.get_model_parameters(), grads)\n",
    "#     )\n",
    "# print(model.fc2.state_dict()[\"weight\"].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Training Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.TensorPointer object at 0x7f2c85bd44c0> <syft.proxy.torch.TensorPointer object at 0x7f2c85bd4400>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/anaconda3/envs/pysyft/lib/python3.9/site-packages/syft/lib/torch/uppercase_tensor.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  grad = getattr(obj, \"grad\", None)\n"
     ]
    }
   ],
   "source": [
    "def set_remote_model_params(module_ptrs, params_list_ptr):\n",
    "    \"\"\"Sets the model parameters into traced model\"\"\"\n",
    "    param_idx = 0\n",
    "    for module_name, module_ptr in module_ptrs.items():\n",
    "        for param_name, _ in PLAN_BUILDER_VM.store[\n",
    "            module_ptr.id_at_location\n",
    "        ].data.named_parameters():\n",
    "            module_ptr.register_parameter(param_name, params_list_ptr[param_idx])\n",
    "            param_idx += 1\n",
    "\n",
    "# Create the model\n",
    "local_model = EmbeddingNet(th,n_users=9)\n",
    "\n",
    "# Dummy inputs\n",
    "bs = 32\n",
    "model_params_zeros = sy.lib.python.List(\n",
    "    [th.nn.Parameter(th.zeros_like(param)) for param in local_model.parameters()]\n",
    ")\n",
    "\n",
    "@make_plan\n",
    "def training_plan(\n",
    "    xs=th.randint(1,8,(bs,)),\n",
    "    xs2=th.randn(bs, 10),\n",
    "    ys=th.rand(bs,1),\n",
    "    batch_size=th.tensor([bs]),\n",
    "    lr=th.tensor([0.01]),\n",
    "    params=model_params_zeros,\n",
    "):\n",
    "    # send the model to plan builder (but not its default params)\n",
    "    # this is required to build the model inside the Plan\n",
    "    model = local_model.send(ROOT_CLIENT, send_parameters=False)\n",
    "\n",
    "    # set model params from input\n",
    "    set_remote_model_params(model.modules, params)\n",
    "    \n",
    "    print(xs,xs2)\n",
    "    # forward\n",
    "    fpass = model(xs,xs2)\n",
    "\n",
    "    # loss\n",
    "    loss, loss_grad = model.mse_loss(fpass,ys,batch_size)\n",
    "\n",
    "    # backward\n",
    "    grads = model.backward(xs, loss_grad)\n",
    "\n",
    "    # SGD step\n",
    "    updated_params = tuple(\n",
    "        param - lr * grad for param, grad in zip(model.parameters(), grads)\n",
    "    )\n",
    "\n",
    "    # return things\n",
    "    return (loss, *updated_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate the training plan to torchscript so it can be used with mobile workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-12-22T03:20:09.543137+0000][CRITICAL][logger]][303705] <class 'syft.core.store.store_memory.MemoryStore'> __getitem__ error <UID: 54316dcb944d483fa5ede01753452ac8> <UID: 54316dcb944d483fa5ede01753452ac8>\n",
      "[2021-12-22T03:20:09.544916+0000][CRITICAL][logger]][303705] <UID: 54316dcb944d483fa5ede01753452ac8>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "<UID: 54316dcb944d483fa5ede01753452ac8>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_303705/2037563193.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Translate to torchscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mts_plan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_to_ts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_plan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Let's examine its contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_plan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorchscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.9/site-packages/syft/core/plan/translation/torchscript/plan_translate.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(plan)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mkwarg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     args = tuple(\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mPLAN_BUILDER_VM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_at_location\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwarg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.9/site-packages/syft/core/plan/translation/torchscript/plan_translate.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     args = tuple(\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mPLAN_BUILDER_VM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_at_location\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwarg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.9/site-packages/syft/core/store/store_memory.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mcritical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{type(self)} __getitem__ error {key} {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mtraceback_and_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStorableObject\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.9/site-packages/syft/logger.py\u001b[0m in \u001b[0;36mtraceback_and_raise\u001b[0;34m(e, verbose)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pysyft/lib/python3.9/site-packages/syft/core/store/store_memory.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUID\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mStorableObject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mcritical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{type(self)} __getitem__ error {key} {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: <UID: 54316dcb944d483fa5ede01753452ac8>"
     ]
    }
   ],
   "source": [
    "# Translate to torchscript\n",
    "ts_plan = translate_to_ts(training_plan)\n",
    "\n",
    "# Let's examine its contents\n",
    "print(ts_plan.torchscript.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Averaging Plan\n",
    "\n",
    "Averaging Plan is executed by PyGrid at the end of the cycle,\n",
    "to average _diffs_ submitted by workers and update the model\n",
    "and create new checkpoint for the next cycle.\n",
    "\n",
    "_Diff_ is the difference between client-trained\n",
    "model params and original model params,\n",
    "so it has same number of tensors and tensor's shapes\n",
    "as the model parameters.\n",
    "\n",
    "We define Plan that processes one diff at a time.\n",
    "Such Plans require `iterative_plan` flag set to `True`\n",
    "in `server_config` when hosting FL model to PyGrid.\n",
    "\n",
    "Plan below will calculate simple mean of each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@make_plan\n",
    "def avg_plan(\n",
    "    avg=List(local_model.get_model_parameters()), item=List(local_model.get_model_parameters()), num=Int(0)\n",
    "):\n",
    "    new_avg = []\n",
    "    for i, param in enumerate(avg):\n",
    "        new_avg.append((avg[i] * num + item[i]) / (num + 1))\n",
    "    return new_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Federated Learning Process Configuration\n",
    "\n",
    "Before hosting the model and training plan to PyGrid,\n",
    "we need to define some configuration parameters, such as\n",
    "FL process name, version, workers configuration,\n",
    "authentication method, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "name = \"mnist\"\n",
    "version = \"1.0\"\n",
    "\n",
    "client_config = {\n",
    "    \"name\": name,\n",
    "    \"version\": version,\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 0.01,\n",
    "    \"max_updates\": 100,  # number of updates to execute on workers\n",
    "}\n",
    "\n",
    "server_config = {\n",
    "    \"num_cycles\": 30,  # total number of cycles (how many times global model is updated)\n",
    "    \"cycle_length\": 60*60*24,  # max duration of the training cycle in seconds\n",
    "    \"max_diffs\": 1,  # number of diffs to collect before updating global model\n",
    "    \"minimum_upload_speed\": 0,\n",
    "    \"minimum_download_speed\": 0,\n",
    "    \"iterative_plan\": True,  # tells PyGrid that avg plan is executed per diff\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This FL process will require workers to authenticate with signed JWT token.\n",
    "Providing the `pub_key` in FL configuration allows PyGrid to verify JWT tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_file(fname):\n",
    "    with open(fname, \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "public_key = read_file(\"example_rsa.pub\").strip()\n",
    "\n",
    "server_config[\"authentication\"] = {\n",
    "    \"type\": \"jwt\",\n",
    "    \"pub_key\": public_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Host in PyGrid\n",
    "\n",
    "Let's now host everything in PyGrid so that it can be accessed by worker libraries.\n",
    "\n",
    "Note: assuming the PyGrid Domain is running locally on port 7000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.1: Start a PyGrid Domain\n",
    "- Clone PyGrid Github repository from https://github.com/OpenMined/PyGrid\n",
    "\n",
    "- Install poetry using pip:\n",
    "```\n",
    "$ pip install poetry\n",
    "```\n",
    "\n",
    "- Go to apps/domain and install requirements:\n",
    "```\n",
    "$ poetry install\n",
    "```\n",
    "\n",
    "- run a Grid domain using the command:\n",
    "```\n",
    "$ ./run.sh --name bob --port 7000 --start_local_db\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grid_address = \"localhost:7000\"\n",
    "grid = ModelCentricFLClient(address=grid_address, secure=False)\n",
    "grid.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code sends FL model, training plans, and configuration to the PyGrid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "response = grid.host_federated_training(\n",
    "    model=local_model,\n",
    "    client_plans={\n",
    "        # Grid can store both types of plans (regular for python worker, torchscript for mobile):\n",
    "        \"training_plan\": training_plan,\n",
    "        \"training_plan:ts\": ts_plan,\n",
    "    },\n",
    "    client_protocols={},\n",
    "    server_averaging_plan=avg_plan,\n",
    "    client_config=client_config,\n",
    "    server_config=server_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'model-centric/host-training', 'data': {'status': 'success'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see successful response, you've just hosted your first FL process into PyGrid!\n",
    "\n",
    "If you see error that FL process already exists,\n",
    "this means FL process with such name and version is already hosted.\n",
    "You might want to update name/version in configuration above, or cleanup PyGrid database.\n",
    "\n",
    "To cleanup database, set path below correctly and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !rm PyGrid/apps/domain/src/nodedatabase.db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To train hosted model, use one of the existing mobile FL workers:\n",
    " * [SwiftSyft](https://github.com/OpenMined/SwiftSyft) (see included worker example)\n",
    " * [KotlinSyft](https://github.com/OpenMined/KotlinSyft) (see included worker example)\n",
    "\n",
    "Support for javascript worker is coming soon:\n",
    " * [syft.js](https://github.com/OpenMined/syft.js)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
