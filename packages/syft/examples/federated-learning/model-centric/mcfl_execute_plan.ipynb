{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import time\n",
    "\n",
    "# third party\n",
    "import jwt\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# syft absolute\n",
    "import syft as sy\n",
    "from syft.federated.fl_client import FLClient\n",
    "from syft.federated.fl_job import FLJob\n",
    "from syft.federated.model_centric_fl_client import ModelCentricFLClient\n",
    "from syft.util import get_root_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7b0623edf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.random.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train FL model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Auth token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fname):\n",
    "    with open(fname, \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_key = read_file(\"example_rsa\").strip()\n",
    "public_key = read_file(\"example_rsa.pub\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_token = jwt.encode({}, private_key, algorithm=\"RS256\").decode(\"ascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyGrid Node address\n",
    "PYGRID_HOST = \"pygrid.datax.io\"\n",
    "PYGRID_PORT = 7000\n",
    "gridAddress = f\"ws://{PYGRID_HOST}:{PYGRID_PORT}\"\n",
    "\n",
    "# Hosted model name/version\n",
    "model_name = \"mnist\"\n",
    "model_version = \"1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Federated Learning Job callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: /home/hinnes/.syft/data\n",
       "    Split: Test"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TorchVision hotfix https://github.com/pytorch/vision/issues/3549\n",
    "\n",
    "# datasets.MNIST.resources = [\n",
    "#     (\n",
    "#         \"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\",\n",
    "#         \"f68b3c2dcbeaaa9fbdd348bbdeb94873\",\n",
    "#     ),\n",
    "#     (\n",
    "#         \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\",\n",
    "#         \"d53e105ee54ea40749a09fcbcd1e9432\",\n",
    "#     ),\n",
    "#     (\n",
    "#         \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\",\n",
    "#         \"9fb629c4189551a2d022fa330f9573f3\",\n",
    "#     ),\n",
    "#     (\n",
    "#         \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\",\n",
    "#         \"ec29112dd5afa0611ce80d1b7f02629c\",\n",
    "#     ),\n",
    "# ]\n",
    "datasets.MNIST(get_root_data_path(), train=True, download=True)\n",
    "datasets.MNIST(get_root_data_path(), train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "train_set = datasets.MNIST(get_root_data_path(), train=True, download=True, transform=tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycles_log = []\n",
    "status = {\"ended\": False}\n",
    "\n",
    "# Called when client is accepted into FL cycle\n",
    "def on_accepted(job: FLJob):\n",
    "    print(f\"Accepted into cycle {len(cycles_log) + 1}!\")\n",
    "\n",
    "    cycle_params = job.client_config\n",
    "    batch_size, max_updates = cycle_params[\"batch_size\"], cycle_params[\"max_updates\"]\n",
    "    training_plan, model_params = job.plans[\"training_plan\"], job.model\n",
    "    losses, accuracies = [], []\n",
    "\n",
    "    train_loader = th.utils.data.DataLoader(\n",
    "        train_set, batch_size=batch_size, drop_last=True, shuffle=True\n",
    "    )\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        y = th.nn.functional.one_hot(y, 10)\n",
    "        (model_params,) = training_plan(xs=x, ys=y, params=model_params)\n",
    "\n",
    "        if batch_idx >= max_updates - 1:\n",
    "            break\n",
    "\n",
    "    job.report(model_params)\n",
    "    # Save losses/accuracies from cycle\n",
    "    cycles_log.append((losses, accuracies))\n",
    "\n",
    "\n",
    "# Called when the client is rejected from cycle\n",
    "def on_rejected(job: FLJob, timeout):\n",
    "    if timeout is None:\n",
    "        print(f\"Rejected from cycle without timeout (this means FL training is done)\")\n",
    "    else:\n",
    "        print(f\"Rejected from cycle with timeout: {timeout}\")\n",
    "    status[\"ended\"] = True\n",
    "\n",
    "\n",
    "# Called when error occured\n",
    "def on_error(job: FLJob, error: Exception):\n",
    "    print(f\"Error: {error}\")\n",
    "    status[\"ended\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_and_run_cycle():\n",
    "    client = FLClient(url=gridAddress, auth_token=auth_token, secure=False)\n",
    "    client.worker_id = client.grid_worker.authenticate(\n",
    "        client.auth_token, model_name, model_version\n",
    "    )[\"data\"][\"worker_id\"]\n",
    "    job = client.new_job(model_name, model_version)\n",
    "\n",
    "    # Set event handlers\n",
    "    job.add_listener(job.EVENT_ACCEPTED, on_accepted)\n",
    "    job.add_listener(job.EVENT_REJECTED, on_rejected)\n",
    "    job.add_listener(job.EVENT_ERROR, on_error)\n",
    "\n",
    "    # Shoot!\n",
    "    job.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted into cycle 1!\n",
      "Accepted into cycle 2!\n",
      "Accepted into cycle 3!\n",
      "Accepted into cycle 4!\n",
      "Accepted into cycle 5!\n",
      "Accepted into cycle 6!\n",
      "Accepted into cycle 7!\n",
      "Accepted into cycle 8!\n",
      "Accepted into cycle 9!\n"
     ]
    }
   ],
   "source": [
    "while not status[\"ended\"]:\n",
    "    create_client_and_run_cycle()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_address = f\"{PYGRID_HOST}:{PYGRID_PORT}\"\n",
    "grid = ModelCentricFLClient(address=grid_address, secure=False)\n",
    "grid.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_params = grid.retrieve_model(model_name, model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super().__init__(torch_ref=torch_ref)\n",
    "        self.l1 = self.torch_ref.nn.Linear(784, 100)\n",
    "        self.a1 = self.torch_ref.nn.ReLU()\n",
    "        self.l2 = self.torch_ref.nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_reshaped = x.view(-1, 28 * 28)\n",
    "        l1_out = self.a1(self.l1(x_reshaped))\n",
    "        l2_out = self.l2(l1_out)\n",
    "        return l2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_params(model, params):\n",
    "    for p, p_new in zip(model.parameters(), params):\n",
    "        p.data = p_new.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model):\n",
    "    correct = []\n",
    "    model.eval()\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        _, pred = th.max(output, 1)\n",
    "        correct.append(th.sum(np.squeeze(pred.eq(target.data.view_as(pred)))))\n",
    "    acc = sum(correct) / len(test_loader.dataset)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(th)\n",
    "set_params(model, trained_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "mnist_test = datasets.MNIST(get_root_data_path(), train=False, transform=tfs)\n",
    "test_loader = th.utils.data.DataLoader(\n",
    "    mnist_test, batch_size=32, shuffle=True, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"accuracy: {test(test_loader, model):.2F}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(test_loader, model, n=6):\n",
    "    xs, ys = next(iter(test_loader))\n",
    "    preds = model(xs).detach()\n",
    "\n",
    "    fig, axs = plt.subplots(1, n, figsize=(16, 8))\n",
    "    for i in range(n):\n",
    "        ax = axs[i]\n",
    "        ax.set_xticks([]), ax.set_yticks([])\n",
    "        ax.set_xlabel(f\"prediction: {np.argmax(preds[i])}, actual: {ys[i]}\")\n",
    "        ax.imshow(xs[i].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a90f535810ebba534c3e17337877525af45b39fe02add77cb71acb6bdc028155"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
